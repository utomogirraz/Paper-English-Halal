@misc{Neo4jLabsteam,
abstract = {This section describes the Adamic Adar algorithm in the Neo4j Graph Data Science library.},
author = {{Neo4j Labs team}},
title = {{Adamic Adar}},
url = {https://neo4j.com/docs/graph-data-science/current/alpha-algorithms/adamic-adar/},
urldate = {2021-07-15}
}
@misc{Neo4jLabsteama,
abstract = {This section describes the Approximate Nearest Neighbors algorithm in the Neo4j Graph Data Science library.},
author = {{Neo4j Labs team}},
title = {{Approximate Nearest Neighbors (ANN)}},
url = {https://neo4j.com/docs/graph-data-science/current/alpha-algorithms/approximate-nearest-neighbors/{\#}alpha-algorithms-approximate-nearest-neighbors},
urldate = {2021-07-15}
}
@article{Foody2020,
abstract = {The kappa coefficient is not an index of accuracy, indeed it is not an index of overall agreement but one of agreement beyond chance. Chance agreement is, however, irrelevant in an accuracy assessment and is anyway inappropriately modelled in the calculation of a kappa coefficient for typical remote sensing applications. The magnitude of a kappa coefficient is also difficult to interpret. Values that span the full range of widely used interpretation scales, indicating a level of agreement that equates to that estimated to arise from chance alone all the way through to almost perfect agreement, can be obtained from classifications that satisfy demanding accuracy targets (e.g. for a classification with overall accuracy of 95{\%} the range of possible values of the kappa coefficient is −0.026 to 0.900). Comparisons of kappa coefficients are particularly challenging if the classes vary in their abundance (i.e. prevalence) as the magnitude of a kappa coefficient reflects not only agreement in labelling but also properties of the populations under study. It is shown that all of the arguments put forward for the use of the kappa coefficient in accuracy assessment are flawed and/or irrelevant as they apply equally to other, sometimes easier to calculate, measures of accuracy. Calls for the kappa coefficient to be abandoned from accuracy assessments should finally be heeded and researchers are encouraged to provide a set of simple measures and associated outputs such as estimates of per-class accuracy and the confusion matrix when assessing and comparing classification accuracy.},
author = {Foody, Giles M.},
doi = {10.1016/j.rse.2019.111630},
file = {:D$\backslash$:/Kuliah/TA/DATA/1-s2.0-S0034425719306509-main.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Accuracy,Bias,Chance,Kappa coefficient,Prevalence},
number = {December 2019},
pages = {111630},
publisher = {Elsevier},
title = {{Explaining the unsuitability of the kappa coefficient in the assessment and comparison of the accuracy of thematic maps obtained by image classification}},
url = {https://doi.org/10.1016/j.rse.2019.111630},
volume = {239},
year = {2020}
}
@misc{Neo4jLabsteamb,
abstract = {this section describes the Preferential Attachment algorithm in the Neo4j Graph Data Science library.},
author = {{Neo4j Labs team}},
title = {{Preferential Attachment}},
url = {https://neo4j.com/docs/graph-data-science/current/alpha-algorithms/preferential-attachment/},
urldate = {2021-07-15}
}
@article{Powers2020,
abstract = {Commonly used evaluation measures including Recall, Precision, F-Measure and Rand Accuracy are biased and should not be used without clear understanding of the biases, and corresponding identification of chance or base case levels of the statistic. Using these measures a system that performs worse in the objective sense of Informedness, can appear to perform better under any of these commonly used measures. We discuss several concepts and measures that reflect the probability that prediction is informed versus chance. Informedness and introduce Markedness as a dual measure for the probability that prediction is marked versus chance. Finally we demonstrate elegant connections between the concepts of Informedness, Markedness, Correlation and Significance as well as their intuitive relationships with Recall and Precision, and outline the extension from the dichotomous case to the general multi-class case.},
archivePrefix = {arXiv},
arxivId = {2010.16061},
author = {Powers, David M. W.},
eprint = {2010.16061},
file = {:D$\backslash$:/Kuliah/TA/DATA/2010.16061.pdf:pdf},
keywords = {correlation,deltap,f-measure,informedness and markedness,kappa,rand accuracy,recall and precision,significance},
pages = {37--63},
title = {{Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation}},
url = {http://arxiv.org/abs/2010.16061},
year = {2020}
}
@article{Ho1992,
author = {Ho, T K and Laboratories, Bell and Ave, Mountain and Hill, Murray and Baja, G Sanniti and Cibernetica, Istituto and Flegrei, Via Campi},
file = {:D$\backslash$:/Kuliah/TA/DATA/IFC--Editorial-Board{\_}2006{\_}Pattern-Recognition-Letters.pdf:pdf},
number = {212},
pages = {80078},
title = {{Pattern Recognition Letters}},
volume = {1992},
year = {1992}
}
@article{Analysis2016,
author = {Analysis, P A R O C and Sammut, In C and Webb, G I},
file = {:D$\backslash$:/Kuliah/TA/DATA/Peter{\_}Flach{\_}ROC{\_}Analysis.pdf:pdf},
isbn = {9781489975027},
pages = {1--8},
title = {{( Eds .), Encyclopedia of Machine Learning and Data Mining ( pp . 1-8 ).}},
year = {2016}
}
@article{IanH.Witten2017,
author = {{Ian H. Witten} and Pa, Christopher J.},
journal = {Data Mining (Fourth Edition)},
title = {{Extending instance-based and linear models}},
url = {https://www.sciencedirect.com/topics/computer-science/euclidean-distance},
year = {2017}
}
@article{Zager2008,
abstract = {We outline a class of graph similarity measures that uses the structural similarity of local neighborhoods to derive pairwise similarity scores for the nodes of two different graphs, and present a related similarity measure that uses a linear update to generate both node and edge similarity scores. This measure is then applied to the task of graph matching. {\textcopyright} 2007 Elsevier Ltd. All rights reserved.},
author = {Zager, Laura A. and Verghese, George C.},
doi = {10.1016/j.aml.2007.01.006},
file = {:D$\backslash$:/Kuliah/TA/DATA/1-s2.0-S0893965907001012-main.pdf:pdf},
issn = {08939659},
journal = {Applied Mathematics Letters},
keywords = {Graph algorithms,Graph alignment,Graph matching,Graphs and networks,Similarity measures},
number = {1},
pages = {86--94},
title = {{Graph similarity scoring and matching}},
volume = {21},
year = {2008}
}
@article{Lin2018,
abstract = {Load curve data from advanced metering infrastructure record the consumers' behavior. User consumption models help one understand a more intelligent power provisioning and clustering the load data is one of the popular approaches for building these models. Similarity measurements are important in the clustering model, but, load curve data is a time series style data, and traditional measurement methods are not suitable for load curve data. To cluster the load curve data more accurately, this paper applied an enhanced Pearson similarity for load curve data clustering. Our method introduces the 'trend alteration point' concept and integrates it with the Pearson similarity. By introducing a weight for Pearson distance, this method helps to keep the whole contour of the load data and the partial similarity. Based on the weighed Pearson distance, a weighed Pearson-based hierarchy clustering algorithm is proposed. Years of load curve data are used for evaluation. Several user consumption models are found and analyzed. Results show that the proposed method improves the accuracy of load data clustering.},
author = {Lin, Rongheng and Wu, Budan and Su, Yun},
doi = {10.3390/en11092466},
file = {:D$\backslash$:/Kuliah/TA/DATA/energies-11-02466.pdf:pdf},
isbn = {8610611981},
issn = {19961073},
journal = {Energies},
keywords = {Clustering algorithm,Pearson similarity,Power load data,Similarity measurement,Smart grid},
number = {9},
pages = {1--17},
title = {{An adaptive weighted pearson similarity measurement method for load curve clustering}},
volume = {11},
year = {2018}
}
@misc{Neo4jLabsteamc,
abstract = {This section describes the Euclidean Distance algorithm in the Neo4j Labs Graph Algorithms library.},
author = {{Neo4j Labs team}},
title = {{9.5.4. The Euclidean Distance algorithm}},
url = {https://neo4j.com/docs/graph-algorithms/current/labs-algorithms/euclidean/{\#}:{~}:text=Euclidean distance measures the straight,and is not officially supported.},
urldate = {22 Desember 2020}
}
@misc{Team,
abstract = {This section describes the Pearson Similarity algorithm in the Neo4j Labs Graph Algorithms library.},
author = {Team, Neo4j Labs},
title = {{9.5.3. The Pearson Similarity algorithm}},
url = {https://neo4j.com/docs/graph-algorithms/current/labs-algorithms/pearson/},
urldate = {2020}
}
@article{Ali2016,
abstract = {The Concept of Halal Food in Sharia Perspective and Product Responsibility of Halal Industry. Sharia provisions regarding halal and haram food, beverages, and goods are integral parts of Islamic teachings. Halal and haram foods also have become a necessity related to the comfort and safety of the Muslims as the largest consumers in Indonesia. This need should be enforced by halal industry. Every manufacturer of halal foods should have an understanding and awareness to ensure their halal products by implementing a Halal Assurance System as the implementation of sharia concept of halal and haram on food and drinks. The violation of Halal Assurance System by the manufacturer will be subject to product liability, both legally and morally.DOI: 10.15408/ajis.v16i2.4459},
author = {Ali, Muchtar},
doi = {10.15408/ajis.v16i2.4459},
file = {:D$\backslash$:/Kuliah/TA/DATA/4459-10772-1-PB.pdf:pdf},
issn = {1412-4734},
journal = {AHKAM : Jurnal Ilmu Syariah},
keywords = {abstraksi,ajaran islam,bagian integral dari,dan,dan berkaitan dengan kenyamanan,dan haramnya makanan,halal,halal dan haramnya makanan,haram,industri,jawab produk atas produsen,juga telah menjadi kebutuhan,ketentuan syariah mengenai halal,konsep makanan halal dalam,manufacturer,minuman dan barang gunaan,product liability,tinjauan syariah dan tanggung},
number = {2},
pages = {291--306},
title = {{Konsep Makanan Halal dalam Tinjauan Syariah dan Tanggung Jawab Produk Atas Produsen Industri Halal}},
volume = {16},
year = {2016}
}
@article{Ye2011,
abstract = {In this work, considering the information carried by the membership degree and the non-membership degree in Atanassov's intuitionistic fuzzy sets (IFSs) as a vector representation with the two elements, a cosine similarity measure and a weighted cosine similarity measure between IFSs are proposed based on the concept of the cosine similarity measure for fuzzy sets. To demonstrate the efficiency of the proposed cosine similarity measures, the existing similarity measures between IFSs are compared with the cosine similarity measure between IFSs by numerical examples. Finally, the cosine similarity measures are applied to pattern recognition and medical diagnosis. {\textcopyright} 2010 Elsevier Ltd.},
author = {Ye, Jun},
doi = {10.1016/j.mcm.2010.07.022},
file = {:D$\backslash$:/Kuliah/TA/DATA/1-s2.0-S0895717710003651-main.pdf:pdf},
issn = {08957177},
journal = {Mathematical and Computer Modelling},
keywords = {Cosine similarity measure,Intuitionistic fuzzy set,Medical diagnosis,Pattern recognition},
number = {1-2},
pages = {91--97},
publisher = {Elsevier Ltd},
title = {{Cosine similarity measures for intuitionistic fuzzy sets and their applications}},
url = {http://dx.doi.org/10.1016/j.mcm.2010.07.022},
volume = {53},
year = {2011}
}
@article{Niwattanakul2013,
abstract = {Presently, information retrieval can be accomplished simply and rapidly with the use of search engines. This allows users to specify the search criteria as well as specific keywords to obtain the required results. Additionally, an index of search engines has to be updated on most recent information as it is constantly changed over time. Particularly, information retrieval results as documents are typically too extensive, which affect on accessibility of the required results for searchers. Consequently, a similarity measurement between keywords and index terms is essentially performed to facilitate searchers in accessing the required results promptly. Thus, this paper proposed the similarity measurement method between words by deploying Jaccard Coefficient. Technically, we developed a measure of similarity Jaccard with Prolog programming language to compare similarity between sets of data. Furthermore, the performance of this proposed similarity measurement method was accomplished by employing precision, recall, and F-measure. Precisely, the test results demonstrated the awareness of advantage and disadvantages of the measurement which were adapted and applied to a search for meaning by using Jaccard similarity coefficient.},
author = {Niwattanakul, Suphakit and Singthongchai, Jatsada and Naenudorn, Ekkachai and Wanapu, Supachanun},
file = {:D$\backslash$:/Kuliah/TA/DATA/IMECS2013{\_}pp380-384.pdf:pdf},
isbn = {9789881925183},
issn = {20780958},
journal = {Lecture Notes in Engineering and Computer Science},
keywords = {Jaccard Coefficient,Prolog programming language,Similarity},
pages = {380--384},
title = {{Using of jaccard coefficient for keywords similarity}},
volume = {2202},
year = {2013}
}
@misc{W3CWorkingGroupNote2014,
abstract = {This primer is designed to provide the reader with the basic knowledge required to effectively use RDF. It introduces the basic concepts of RDF and shows concrete examples of the use of RDF. Secs. 3-5 can be used as a minimalist introduction into the key elements of RDF. Changes between RDF 1.1 and RDF 1.0 (2004 version) are summarized in a separate document: "What's New in RDF 1.1"},
author = {{W3C Working Group Note}},
title = {{RDF 1.1 Primer}},
url = {https://www.w3.org/TR/rdf11-primer/},
urldate = {2020-12-03},
year = {2014}
}
@book{Bauer2012,
abstract = {This introductory text describes the principles of linking data; defines important terms such as Open Government, Open (Government) Data and Linked Open (Government) Data; and explains relevant mechanisms to ensure a solid foundation before going more in-depth. It makes the case for using Linked Open Data, and offers a set of case studies from the energy industry and relating to legislation.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bauer, Florian and Kaltenb{\"{o}}ck, Martin},
eprint = {arXiv:1011.1669v3},
file = {:D$\backslash$:/Kuliah/TA/DATA/LOD-the-Essentials{\_}0.pdf:pdf},
isbn = {978-3-902796-05-9},
issn = {10580530},
pages = {62},
pmid = {25246403},
title = {{Linked Open Data: A Quick Start Guide for Decision Makers}},
url = {http://www.semantic-web.at/LOD-TheEssentials.pdf},
year = {2012}
}
@misc{Neo4jLabsteamd,
abstract = {This section describes the Jaccard Similarity algorithm in the Neo4j Labs Graph Algorithms library.},
author = {{Neo4j Labs team}},
title = {{The Jaccard Similarity algorithm}},
url = {https://neo4j.com/docs/graph-algorithms/current/labs-algorithms/jaccard/},
urldate = {2020-12-03}
}
@misc{Berners-Lee2009,
author = {Berners-Lee, Tim},
title = {{Linked Data}},
url = {https://www.w3.org/DesignIssues/LinkedData},
urldate = {2020-12-03},
year = {2009}
}
@misc{Neo4jLabsteame,
abstract = {This section describes the Cosine Similarity algorithm in the Neo4j Labs Graph Algorithms library.},
author = {{Neo4j Labs team}},
title = {{9.5.2. The Cosine Similarity algorithm}},
url = {https://neo4j.com/docs/graph-algorithms/current/labs-algorithms/cosine/},
urldate = {2020-12-03}
}
@misc{RDFWorkingGroup2014,
abstract = {RDF is a standard model for data interchange on the Web. RDF has features that facilitate data merging even if the underlying schemas differ, and it specifically supports the evolution of schemas over time without requiring all the data consumers to be changed. RDF extends the linking structure of the Web to use URIs to name the relationship between things as well as the two ends of the link (this is usually referred to as a “triple”). Using this simple model, it allows structured and semi-structured data to be mixed, exposed, and shared across different applications. This linking structure forms a directed, labeled graph, where the edges represent the named link between two resources, represented by the graph nodes. This graph view is the easiest possible mental model for RDF and is often used in easy-to-understand visual explanations.},
author = {{RDF Working Group}},
title = {{RDF}},
url = {https://www.w3.org/RDF/},
urldate = {2020-12-03},
year = {2014}
}
@article{Grover2016,
abstract = {Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-ofthe- art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning stateof- the-art task-independent representations in complex networks.},
author = {Grover, Aditya and Leskovec, Jure},
journal = {KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {Feature learning,Graph representations.,Information networks,Node embeddings},
pages = {855--864},
title = {{node2vec: Scalable Feature Learning for Networks}},
url = {https://doi.org/10.1145/2939672.2939754},
year = {2016}
}
@article{Tsitsulin2018,
abstract = {Embedding a web-scale information network into a low-dimensional vector space facilitates tasks such as link prediction, classification, and visualization. Past research has addressed the problem of extracting such embeddings by adopting methods from words to graphs, without defining a clearly comprehensible graph-related objective. Yet, as we show, the objectives used in past works implicitly utilize similarity measures among graph nodes. In this paper, we carry the similarity orientation of previous works to its logical conclusion; we propose VERtex Similarity Embeddings (VERSE), a simple, versatile, and memory-efficient method that derives graph embeddings explicitly calibrated to preserve the distributions of a selected vertex-to-vertex similarity measure. VERSE learns such embeddings by training a single-layer neural network. While its default, scalable version does so via sampling similarity information, we also develop a variant using the full information per vertex. Our experimental study on standard benchmarks and real-world datasets demonstrates that VERSE, instantiated with diverse similarity measures, outperforms state-of-the-art methods in terms of precision and recall in major data mining tasks and supersedes them in time and space efficiency, while the scalable sampling-based variant achieves equally good result as the non-scalable full variant.},
archivePrefix = {arXiv},
arxivId = {1803.04742},
author = {Tsitsulin, Anton and Mottin, Davide and Karras, Panagiotis and M{\"{u}}ller, Emmanuel},
doi = {10.1145/3178876.3186120},
eprint = {1803.04742},
file = {:D$\backslash$:/Kuliah/TA/DATA/VERSE{\_}Versatile{\_}Graph{\_}Embeddings{\_}from{\_}Similarity{\_}M.pdf:pdf},
isbn = {9781450356398},
journal = {The Web Conference 2018 - Proceedings of the World Wide Web Conference, WWW 2018},
keywords = {Feature learning,Graph embedding,Graph representations,Information networks,Node embedding,Vertex similarity},
pages = {539--548},
title = {{VERSE: Versatile graph embeddings from similarity measures}},
year = {2018}
}
@article{Salman2011,
abstract = {The purpose of this study is to measure the awareness and perception of halal food in Pakistan which is predominantly a Muslim country. Design/methodology/approach – The study is exploratory in nature and cross sectional data has been obtained from 528 respondents belonging to two major clusters-university students and corporate sector. Empirical data was collected through survey methodology. Three statistical tools have been used for data analysis ; (a) Cronbach's alpha; (b) Confirmatory Factor Analysis and ; (c) Pearson product correlation matrix. Findings – The author purports that; (a) religion is the omnipotent source of religious beliefs for Muslims Consumers; (b) Beliefs are closely knitted with religious commitment; (c) People who are highly religious may not necessarily have high level of awareness about halal food; (d) Attitude towards halal food is closely akin to the notion of beliefs;(e) The dogma of identity is more linked with intrinsic rather than extrinsic forces. Research limitations/implications – The study focuses on two major clusters and the data is obtained through cluster sampling. The researcher measures general awareness and perceptions of consumers regarding halal food. However further research is suggested to nudge deeply in the concept of halal logo and dimension of halal brand amongst the Muslim consumers. Practical implications- Although Pakistani is a by and large a Muslim country but there is very little awareness regarding Halal food unlike other Muslim states such as Indonesia and Malaysia. The country has no formal Halal certification issuing body. The findings of this research will be of great significance to the marketers and food manufactures in Pakistan who will find new avenues to delve into halal food certification business, and endeavor into Muslim markets as the producers of certified halal food. Originality/value – Although Islamic marketing is the new buzz word but religion and consumer behavior largely remains untapped by academic researchers. There is lack of empirically tested knowledge about the awareness and perceptions towards Halal foods among Pakistani consumers. The research will be a valuable addition in propagation of knowledge on the subject area},
author = {Salman, Faryal and {KAMRAN SIDDIQUI}},
file = {:D$\backslash$:/Kuliah/TA/DATA/SSRN-id2449144.pdf:pdf},
journal = {Interdisciplinary Journal of Contemporary Research in Business},
keywords = {awareness,consumer behavior,halal,muslim consumer,perceptions,religion},
number = {2},
pages = {639--651},
title = {{An exploratory study for measuring consumers awareness and perceptions towards halal food in Pakistan}},
volume = {3},
year = {2011}
}
@article{Golnaz2012,
author = {Golnaz, R and Zainalabidin, M and {Mad Nasir}, S},
file = {:D$\backslash$:/Kuliah/TA/DATA/JSSH Vol. 20 (1) Mar. 2012 (View Full Journal).pdf:pdf},
issn = {01287702},
journal = {Pertanika Journal of Social Science and Humanities},
number = {1},
pages = {33--42},
title = {{Assessment of consumers' confidence on Halal labeled manufactured food in Malaysia}},
url = {http://psasir.upm.edu.my/id/eprint/57738/1/JSSH Vol. 20 {\%}281{\%}29 Mar. 2012 {\%}28View Full Journal{\%}29.pdf{\#}page=47},
volume = {20},
year = {2012}
}
@article{Petkovic2020,
abstract = {Background: Understanding the content of self-reported meals and online-published recipes is a basic requirement for further linking food and dietary concepts to heterogeneous health networks. Despite the huge amount of work that is done in the biomedical domain, the food and nutrition domains are relatively low-resourced. DIETHUB represents a step forward in food science {\&} technology that requires knowledge from a broad spectrum of areas. Scope and approach: DIETHUB is an AI workflow methodology that annotates online-published recipes or self-reported meals with the food concepts that are mentioned in them. The food semantic labels that are used are hierarchical food semantic tags from the Hansard taxonomy. DIETHUB overviews and exploits several state-of-the-art methods from two areas of AI: representation learning and predictive modelling. We evaluated DIETHUB by applying it on a corpus of online-published recipes of different styles, such as health, cooking and region. Once the selected recipes were annotated, we compared them considering their styles. The results show justifiable comparison of Mediterranean diet recipes with recipes from other diets. Key Findings and Conclusions: The experimental evaluation reveals that DIETHUB has high predictive power and correctly annotate the recipes with semantic tags. The analysis of the annotations shows that there is no statistically significant difference between Mediterranean diet and each of the diets: diabetic, weight loss, heart healthy recipes, low fat, low calorie, high fiber, and dairy free. All in all, the presented work shows that DIETHUB can be successfully used to analyze corpora of food-related textual documents and provide a deeper insight into the human dietary behaviour.},
author = {Petkovi{\'{c}}, Matej and Popovski, Gorjan and Seljak, Barbara Korou{\v{s}}i{\'{c}} and Kocev, Dragi and Eftimov, Tome},
doi = {10.1016/j.tifs.2020.10.017},
file = {:D$\backslash$:/Kuliah/TA/DATA/1-s2.0-S0924224420306403-main.pdf:pdf},
issn = {09242244},
journal = {Trends in Food Science and Technology},
keywords = {Dietary habits analysis,Hierarchical multi-label classification,food Semantic annotation},
number = {April},
title = {{DIETHUB: Dietary habits analysis through understanding the content of recipes}},
year = {2020}
}
@article{Ispirova2020,
abstract = {Assessing nutritional content is very relevant for patients suffering from various diseases, professional athletes, and for health reasons is becoming part of everyday life for many. However, it is a very challenging task as it requires complete and reliable sources. We introduce a machine learning pipeline for predicting macronutrient values of foods using learned vector representations from short text descriptions of food products. On a dataset used from health specialists, containing short descriptions of foods and macronutrient values: we generate paragraph embeddings, introduce clustering in food groups, using graph-based vector representations, that include food domain knowledge information, and train regression models for each cluster. The predictions are for four macronutrients: carbohydrates, fat, protein and water. The highest accuracy was obtained for carbohydrate predictions – 86{\%}, compared to the baseline – 27{\%} and 36{\%}. The protein predictions yielded the best results across all clusters, 53{\%}–77{\%} of the values fall in the tolerance-level range. These results were obtained using short descriptions, the embeddings can be improved if they are learned on longer descriptions, which would lead to better prediction results. Since the task of calculating macronutrients requires exact quantities of ingredients, these results obtained only from short description are a huge leap forward.},
author = {Ispirova, Gordana and Eftimov, Tome and Seljak, Barbara Korou{\v{s}}i{\'{c}}},
doi = {10.3390/math8101811},
file = {:D$\backslash$:/Kuliah/TA/DATA/mathematics-08-01811.pdf:pdf},
isbn = {3861477351},
issn = {22277390},
journal = {Mathematics},
keywords = {Data mining,Machine learning,Macronutrient prediction,Paragraph embeddings,Representation learning,Single-target regression,Word embeddings},
number = {10},
pages = {1--21},
title = {{P-nut: Predicting nutrient content from short text descriptions}},
volume = {8},
year = {2020}
}
@article{Rakhmawati2019,
abstract = {The life of a Muslim cannot be separated from the concept of halal in his daily life, especially in food. Indonesia is a country that its major population is Muslim. In Indonesia, Institute For Foods, Drugs, And Cosmetics Indonesian Council Of Ulama as known as LPPOM MUI is an organisation that provides halal food product information. However, lack of information is presented on LPPOM MUI site. Therefore, LODHalal, a Linked Open Data system for halal products is proposed. We introduce a halal vocabulary which extends two food vocabularies. Then, collected data from LPPOM MUI, E-Number, Open Food Facts are transformed to RDF. Also, the RDF data are connected to DBpedia, PubChem and Mesh. We develop a web application and an Android application which provides recommendations on the halal and nutritional status of a food product.},
author = {Rakhmawati, Nur Aini and Fatawi, Jauhar and Najib, Ahmad Choirun and Firmansyah, Azmi Adi},
doi = {10.1016/j.jksuci.2019.04.004},
file = {:D$\backslash$:/Kuliah/TA/DATA/1-s2.0-S1319157818312680-main.pdf:pdf},
issn = {22131248},
journal = {Journal of King Saud University - Computer and Information Sciences},
keywords = {Food product,Halal,Linked data,Nutrition},
number = {xxxx},
publisher = {King Saud University},
title = {{Linked open data for halal food products}},
url = {https://doi.org/10.1016/j.jksuci.2019.04.004},
year = {2019}
}
@article{Webber2012,
abstract = {In this workshop we provide a hands-on introduction to the popular open source graph database Neo4j [1] through fixing a series of increasingly sophisticated, but broken, test cases each of which highlights an important graph modeling or API affordance.},
author = {Webber, Jim},
doi = {10.1145/2384716.2384777},
file = {:D$\backslash$:/Kuliah/TA/DATA/webber2012.pdf:pdf},
isbn = {9781450315630},
journal = {SPLASH'12 - Proceedings of the 2012 ACM Conference on Systems, Programming, and Applications: Software for Humanity},
keywords = {Graph Databases,JVM.,Java,NOSQL,Neo4j},
pages = {217},
title = {{A programmatic introduction to Neo4J}},
year = {2012}
}
@phdthesis{ALKAUTSAR2019,
abstract = {Indonesia merupakan salah satu negara dengan mayoritas penduduk muslim terbesar di dunia. Prosentase Muslim Indonesia mencapai 12,7 persen dari populasi dunia. Dari 205 juta penduduk Indonesia, dilaporkan sedikitnya 88,1 persen beragama Islam. Meskipun begitu kita ketahui bahwa negara selain Indonesia juga memiliki banyak penduduk muslim. Oleh karena umat muslim sangat memperhatikan hal mengenai makanan apakah makanan tersebut halal atau tidak sehingga, dibutuhkan sesuatu yang dapat membantu umat muslim mengenai hal tersebut. Saat ini telah ada aplikasi Halal Nutrition Food yang mana pengguna dapat melakukan pengecekan produk halal yang terdapat dalam aplikasi tersebut serta hal-hal lainnya yang disediakan aplikasi Halal Nutrition Food. Terdapat beberapa penelitian yang dilakukan untuk mengembangkan aplikasi ini, salah satunya tugas akhir ini. Tugas akhir ini merupakan bagian dari pengembangan website Halal Nutrition Food dimana pengembangan yang dilakukan merupakan pengumpulan data dari 10 lembaga sertifikasi dari berbagai negara, yang memiliki list produk pada website masing-masing lembaga tersebut. Data yang di dapat akan dihitung similaritasnya dan diintegrasikan dengan data yang sudah ada pada website Halal Nutrition Food. Tugas akhir ini bermanfaat untuk meningkatkan kepercayaan pengguna terhadap produk-produk yang ada pada website Halal Nutrition Food.},
author = {ALKAUTSAR},
file = {:D$\backslash$:/Kuliah/TA/Alkautsar{\_}bukuTA.pdf:pdf},
keywords = {Halal Nutrition Food,integrasi,lembaga sertifikasi,similarity},
school = {Institut Teknologi Sepuluh November},
title = {{INTEGRASI DATA LEMBAGA SERTIFIKASI HALAL DI DUNIA DENGAN DATA HALAL NUTRITION FOOD INTEGRATION OF HALAL CERTIFICATION BODIES DATA FROM AROUND THE WORLD WITH HALAL NUTRITION FOOD DATA}},
year = {2019}
}
@article{Bizer2011,
abstract = {The World Wide Web has enabled the creation of a global information space comprising linked documents. As the Web becomes ever more enmeshed with our daily lives, there is a growing desire for direct access to raw data not currently available on the Web or bound up in hypertext documents. Linked Data provides a publishing paradigm in which not only documents, but also data, can be a first class citizen of the Web, thereby enabling the extension of the Web with a global data space based on open standards - the Web of Data. In this Synthesis lecture we provide readers with a detailed technical introduction to Linked Data. We begin by outlining the basic principles of Linked Data, including coverage of relevant aspects of Web architecture. The remainder of the text is based around two main themes - the publication and consumption of Linked Data. Drawing on a practical Linked Data scenario, we provide guidance and best practices on: architectural approaches to publishing Linked Data; choosing URIs and vocabularies to identify and describe resources; deciding what data to return in a description of a resource on the Web; methods and frameworks for automated linking of data sets; and testing and debugging approaches for Linked Data deployments. We give an overview of existing Linked Data applications and then examine the architectures that are used to consume Linked Data from the Web, alongside existing tools and frameworks that enable these. Readers can expect to gain a rich technical understanding of Linked Data fundamentals, as the basis for application development, research or further study.Table of Contents: List of Figures / Introduction / Principles of Linked Data / The Web of Data / Linked Data Design Considerations / Recipes for Publishing Linked Data / Consuming Linked Data / Summary and Outlook},
author = {Bizer, Christian and Heath, Tom and Berners-Lee, Tim},
doi = {10.4018/978-1-60960-593-3.ch008},
file = {:D$\backslash$:/Kuliah/TA/DATA/linked-data--the-story-so-far.pdf:pdf},
isbn = {9781609605933},
journal = {Semantic Services, Interoperability and Web Applications},
pages = {205--227},
title = {{Linked Data}},
year = {2011}
}
@phdthesis{JANNAH2019,
abstract = {Halal Nutrition Food merupakan produk riset berupa aplikasi yang memberikan pengguna informasi tentang produk makanan halal. Tidak hanya itu, Halal Nutrition Food juga menyediakan informasi nutrisi dan komposisi dari produk tersebut. Namun, data yang ada pada aplikasi ini masih perlu diperkaya dan diolah kembali. Open Food Facts merupakan situs yang menyediakan database mengenai produk makanan (seperti nama produk, komposisi, zat aditif) dimana semua orang di berbagai belahan dunia bisa berkontribusi untuk menambahkan data ke dalamnya maupun menggunakan kembali data yang ada. Pada tugas akhir ini dilakukan pengambilan data dari open food facts kemudian diintegrasikan dengan data pada aplikasi halal nutrition food. Data produk yang akan diintegrasikan diunduh dari situs web open food facts. Data yang ada sangat kotor dan perlu diolah sebelum dilakukan ke proses selanjutnya. Data tersebut diolah pada proses pre-processing data sedemikian rupa sehingga data yang ada dapat diolah ke proses pengukuran kemiripan data. Untuk mengurangi redundansi pada data bahan makanan, penulis melakukan pengukuran kemiripan bahan makanan menggunakan pengukuran kemiripan konseptual dengan Wordnet yang mengukur kemiripan antara dua dataset secara makna kata (sinonim). Selain itu, penulis juga mengukur kemiripan bahan makanan secara tekstual dengan fuzzy string matching, yaitu Levenshtein distance, Jaro-Winkler distance,dan Jaccard distance. Setelah pengukuran kemiripan bahan makanan dilakukan, hasil pengukuran kemiripan diuji untuk mengetahui akurasinya. Dari pengujian tersebut, ditemukan bahwa kombinasi pengukuran kemiripan menggunakan Levenshtein distance (tekstual) dan Wordnet similarity (konseptual) adalah yang paling optimal mengukur kemiripan data bahan makanan sehingga bahan makanan yang diintegrasikan bebas dari redundansi.},
author = {JANNAH, MIFTAHUL},
file = {:D$\backslash$:/Kuliah/TA/05211540000153-Undergraduate{\_}Theses.pdf:pdf},
keywords = {halal,integrasi.,jaccard distance,jaro-winkler distance,levenshtein distance,open food facts,wordnet},
pages = {1--95},
school = {Institut Teknologi Sepuluh November},
title = {{INTEGRASI DATA PRODUK HALAL BERDASARKAN INTEGRATION OF DATA HALAL PRODUCTS BASED ON SIMILARITY DISTANCE OF CONSEPTUAL AND TEXTUAL OF WORDS}},
year = {2019}
}
@article{Huang2016,
abstract = {Convolutional Neural Networks (CNNs) have recently achieved remarkably strong performance on sentence classification tasks (Kim, 2014; Kalchbrenner et al.,2014; Wang et al., 2015). However, these models require practitioners to specify the exact model architecture and accompanying hyper-parameters, e.g., the choice of filter region size, regularization parameters, and so on. It is currently unknown how sensitive model performance is to changes in these configurations for the task of sentence classification. We thus conduct an empirical sensitivity analysis of one-layer CNNs to explore the effect of each part of the architecture on the performance; our aim is to assess the robustness of the model and to distinguish between important and comparatively inconsequential design decisions for sentence classification. We focus on one-layer CNNs (to the exclusion of more complex models) due to their comparative simplicity and strong empirical performance (Kim, 2014). We derive practical advice from our extensive empirical results for those interested in getting the most out of CNNs for sentence classification.},
archivePrefix = {arXiv},
arxivId = {arXiv:1306.5204v1},
author = {Huang, Yanxiang and Yu, Lele and Wang, Xiang and Cui, Bin and Vergara, Pierluigi and Qian, Y and Tang, Jessica A. and Yang, Z and Huang, B and Wei, Wei and Zhang, Ye and Wallace, Byron and Kumar, Sumeet and Carley, Kathleen Mary KM M. and Hirshman, Brian R. and Jones, Laurie A. and Carroll, Kate T. and Tang, Jessica A. and Proudfoot, James A. and Carley, Kathleen Mary KM M. and Carter, Bob S. and Chen, Clark C. and Kumar, Sumeet and Carley, Kathleen Mary KM M. and Morgan, G. P. and Lanham, M. J. and Yu, Lele and Shao, Yingxia and Cui, Bin and Mikolov, Tomas and Le, Quoc V and Sutskever, Ilya and Wei, Wei and Joseph, Kenneth and Liu, Huan and Carley, Kathleen Mary KM M. and Carley, Kathleen Mary KM M. and Koren, Yehuda and Ave, Park and Park, Florham and Management, H Database and Applications, Database and Joseph, Kenneth and Carley, Kathleen Mary KM M. and Chen, Liang and Mao, Ying and Sigkdd, A C M and Sigkdd, A C M and Morstatter, Fred and Pfeffer, J and Liu, Huan and Carley, Kathleen Mary KM M. and Lynch, Merrill and Bank, Mellon and Ahuja, Aman and Carley, Kathleen Mary KM M. and Mosquera, C and Koutlas, N J and Fitzgerald, T L and Carley, Kathleen Mary KM M. and Grover, Aditya and Cui, Bin and Jiang, Jie and Huang, Quanlong and Xu, Ying and Gui, Yanjun and Zhang, Wenyu and Na, Seung-Hoon and Kang, In-Su and Lee, Sang-Yool and Lee, Jong-Hyeok and Huang, Yanxiang and Cui, Bin and Jiang, Jie and Hong, Kunqiang and Zhang, Wenyu and Xie, Yiran and Cui, Bin and Kumar, Sumeet and Benigni, Matthew and Carley, Kathleen Mary KM M. and In, Surgery and Field, High and Lo, Caroline and Frankowski, Dan},
eprint = {arXiv:1306.5204v1},
file = {:D$\backslash$:/Kuliah/TA/DATA/grover2016{\_}2.pdf:pdf},
isbn = {9781509038657},
issn = {07308078},
journal = {World Neurosurgery},
keywords = {Anaplastic astrocytoma,Evidence-based medicine,Extent of resection,Glioblastoma,High-grade glioma (HGG),Pig,Real-time,Steam processing,Storm,agent-based model,all or part of,b,big data,collaborative filtering,computational social science,confidence software technologies,cui,dependency analysis,dings,distributed system,dynamic-network,factor graph model,feature learning,feature selection,graph representations,high-grade gastroenteropancreatic neuroendocrine t,huang,identity,incidence,information networks,key lab of high,l,location inference,matrix computing,moe,multi-level modeling,multi-source integration,network,node embed-,occupation inference,online ma-,or,or hard copies of,peking university,permission to make digital,pig,prognostic factors,real-time,real-time collaborative filtering,recommender systems,school of eecs,simulation,social,social media,social psychology,steam processing,stereo-,storm,survival,this work for personal,trix factorization,user profile modeling,video recommendation,wang,x,y,yu},
number = {1},
pages = {41--50},
pmid = {463165},
title = {{node2vec Real-time Video Recommendation Exploration Categories and Subject Descriptors}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.1745{\%}5Cnhttp://link.springer.com/10.1007/s41019-015-0002-9{\%}5Cnhttp://dx.doi.org/10.1016/j.ejso.2016.07.137{\%}5Cnhttp://www.aaai.org/ocs/index.php/ICWSM/ICWSM13/paper/viewPDFInterstitial/6071/6379{\%}5C},
volume = {95},
year = {2016}
}
@article{Huo2020,
abstract = {In the field of electronic record management, especially in the current big data environment, data continuity has become a new topic that is as important as security and needs to be studied. This paper decomposes the data continuity guarantee of electronic record into a set of data protection requirements consisting of data relevance, traceability and comprehensibility, and proposes to use the associated data technology to provide an integrated guarantee mechanism to meet the above three requirements.},
author = {Huo, Yuyi and Zhou, Shi and Hu, Ruiguo and Ren, Yongjun and Xia, Jinyue},
doi = {10.32604/jcs.2020.010963},
file = {:D$\backslash$:/Kuliah/TA/DATA/out.pdf:pdf},
issn = {2579-0064},
journal = {Journal of Cyber Security},
keywords = {data continuity,electronic record,guarantee mechanism},
number = {3},
pages = {151--156},
title = {{Guarantee Mechanism of Data Continuity for Electronic Record Based on Linked Data}},
volume = {2},
year = {2020}
}
@article{Tomaszuk2020,
abstract = {Resource Description Framework (RDF) can seen as a solution in today's landscape of knowledge representation research. An RDF language has symmetrical features because subjects and objects in triples can be interchangeably used. Moreover, the regularity and symmetry of the RDF language allow knowledge representation that is easily processed by machines, and because its structure is similar to natural languages, it is reasonably readable for people. RDF provides some useful features for generalized knowledge representation. Its distributed nature, due to its identifier grounding in IRIs, naturally scales to the size of the Web. However, its use is often hidden from view and is, therefore, one of the less well-known of the knowledge representation frameworks. Therefore, we summarise RDF v1.0 and v1.1 to broaden its audience within the knowledge representation community. This article reviews current approaches, tools, and applications for mapping from relational databases to RDF and from XML to RDF. We discuss RDF serializations, including formats with support for multiple graphs and we analyze RDF compression proposals. Finally, we present a summarized formal definition of RDF 1.1 that provides additional insights into the modeling of reification, blank nodes, and entailments.
MSC Codes H.2.0},
archivePrefix = {arXiv},
arxivId = {2001.00432},
author = {Tomaszuk, Dominik and Hyland-Wood, David},
doi = {10.3390/sym12010084},
eprint = {2001.00432},
file = {:D$\backslash$:/Kuliah/TA/DATA/symmetry-12-00084.pdf:pdf},
issn = {2073-8994},
journal = {arXiv},
keywords = {binary rdf,blank node,complexity,compression,data integration,data model,entailment,linked data,rdf,rdfs,reification,semantic web},
pages = {1--33},
title = {{RDF 1.1: Knowledge representation and data integration language for the web}},
year = {2020}
}
@article{Hogan2020,
author = {Hogan, Aidan and Hogan, Aidan},
doi = {10.1007/978-3-030-51580-5_4},
file = {:D$\backslash$:/Kuliah/TA/DATA/978-3-030-51580-5{\_}4.pdf:pdf},
isbn = {9783030515805},
journal = {The Web of Data},
pages = {111--183},
title = {{RDF Schema and Semantics}},
year = {2020}
}
@article{Mukidi2020,
abstract = {Businessmen have the duty of ensuring halal food products and giving the halal label on the basis of having obtained a halal certificate from the ministry of religion which was socialized to the consumer society in a way that it is conveyed through writings that are easy to read and not easily removed by a visitor at a particular place in the restaurant. It is according to Article 39 of Law Number 33 Year 2014 concerning the guarantee of halal products. The halal certificate is valid for four years since it was issued by the Halal Product Guarantee Agency (HPGA), and it must be extended. Halal certificates are mandatory, so the food products which do not have halal label certificate cannot longer circulate in Indonesia. The procedure for obtaining halal certification at the hotel restaurant which was issued by the Ministry of Religious Affairs (MORA). First, businessmen must fulfill the requirements which were checked by HPGA such as, the data of businessmen, the name and type of business product, a list of products and materials used, the manner or the product processing as well as halal guarantee system. After fulfilling the requirements of HPGA in checking the dokumen, then determine the LPH that has been selected by the applicant, then the LPH conducts the examination and / or testing of the next step of the MUI product through the determination of the halal food product halal through a halal fatwa session. After the process is carried out through the prescribed stages, the HPGA issues a halal certificate},
author = {Mukidi},
file = {:D$\backslash$:/Kuliah/TA/DATA/2674-6594-1-SM.pdf:pdf},
journal = {JURNAL HUKUM KAIDAH Media},
keywords = {halal,halal label certification,halal product protection guarantees,products},
title = {{Prosedur Pemberian Sertifikat Label Halal Terhadap Produk Makanan Di Restoran Hotel Syariah Untuk Mewujudkan Hak Kenyamanan Konsumen Muslim}},
volume = {19},
year = {2020}
}
@article{Svinarky2020,
abstract = {Consumers who are Muslim basically have concerns to buy food that does not have an official halal logo from the institution that has the right to issue. Indonesian consumers who are predominantly Muslim will be more focused on the halal logo listed on a packaging product. However, the logo must first be submitted to BPJPH by the entrepreneur. After the entrepreneur gets the halal certificate, then the halal logo can be placed on the product label. Researchers in this writing use this type of normative legal research. In the type of research the writer uses normative yuridis law as it support. After the establishment of the BPJPH based on the provisions of the presidential regulation in accordance with Article 5 of the UUJPH, the authority of the BPJPH is clearly stated in Article 6. The procedures specified in the explanation of UUJPH, the researcher can also elaborate on the procedure of obtaining Halal certificate which starts with: the request is submitted by the applicant to get a halal certificate to BPJPH. After that the document inspection is carried out by BPJPH, then testing and the inspection is carried out by LPH which has accreditation from BPJPH in collaboration with MUI. Furthermore, the fatwa trial was conducted by MUI to legalize the halal status of a product in the form of a Decision on Halal Product Determination signed by MUI},
author = {Svinarky, Irene and Malau, Parningotan},
doi = {https://doi.org/10.33884/jck.v8i1.1896},
file = {:D$\backslash$:/Kuliah/TA/DATA/1896-85-6569-1-10-20200512.pdf:pdf},
journal = {Jurnal Cahaya Keadilan},
keywords = {Halal Certificate,Halal logo,Legal perspective.,Publishing},
number = {April},
pages = {71--85},
title = {{PENERBITAN SERTIFIKAT HALAL BERDASARKAN PRESPEKTIF HUKUM DI INDONESIA}},
volume = {8},
year = {2020}
}
@article{Rakhmawati2018,
abstract = {Although Indonesia is the world the world's most populous Muslim-majority country, the number of halal-certified products in Indonesia is only 20{\%} of the products on the Indonesian market. Halal certification is voluntary as such there are many food products which are halal but are not certified as halal. In principle, these food products may have similar halal ingredients with halal-certified products. In this study, we build a system that can compare products that have not been certified halal with halal certified products based on its ingredients. The food products are collected from Open Food Facts, Institute For Foods, Drugs, And Cosmetics Indonesian Council Of Ulama (LPPOM MUI) and our halal system. As of this paper writing, the halal-certified products are obtained from LPPOM MUI. The system uses the Euclidean Distance and Cosine Similarity that generate top-5 similar products. Those two similarity calculations are based on Term Frequency-Inverse Entity Frequency weighting function. The weighting function calculates the frequency of a term on a product name and ingredients. If a similarity value of a product with no halal certification and a halal-certified product is higher than 75{\%}, then the former could be indicated as a halal product. In the end, the system can give a recommendation of unknown products from a related pool of halal-certified products based on similarity of product composition. Cosine similarity accuracy is higher than Euclidean Distance and MoreLikeThis accuracy. Cosine similarity gets the highest precision because the cosine similarity is based on the vector angle of the term in a product.},
author = {Rakhmawati, Nur Aini and Firmansyah, Azmi Adi and Effendi, Pradita Maulidya and Abdillah, Rosyid and Cahyono, Taufiq Agung},
doi = {10.18517/ijaseit.8.4-2.7083},
file = {:D$\backslash$:/Kuliah/TA/DATA/296918848.pdf:pdf},
issn = {24606952},
journal = {International Journal on Advanced Science, Engineering and Information Technology},
keywords = {Cosine similarity,Euclidean distance,Halal,Ingredients},
number = {4-2},
pages = {1706--1711},
title = {{Auto Halal detection products based on euclidian distance and cosine similarity}},
volume = {8},
year = {2018}
}
@article{Haussmann2019,
abstract = {The proliferation of recipes and other food information on the Web presents an opportunity for discovering and organizing diet-related knowledge into a knowledge graph. Currently, there are several ontologies related to food, but they are specialized in specific domains, e.g., from an agricultural, production, or specific health condition point-of-view. There is a lack of a unified knowledge graph that is oriented towards consumers who want to eat healthily, and who need an integrated food suggestion service that encompasses food and recipes that they encounter on a day-to-day basis, along with the provenance of the information they receive. Our resource contribution is a software toolkit that can be used to create a unified food knowledge graph that links the various silos related to food while preserving the provenance information. We describe the construction process of our knowledge graph, the plan for its maintenance, and how this knowledge graph has been utilized in several applications. These applications include a SPARQL-based service that lets a user determine what recipe to make based on ingredients at hand while taking constraints such as allergies into account, as well as a cognitive agent that can perform natural language question answering on the knowledge graph. Resource Website: https://foodkg.github.io},
author = {Haussmann, Steven and Seneviratne, Oshani and Chen, Yu and Ne'eman, Yarden and Codella, James and Chen, Ching Hua and McGuinness, Deborah L. and Zaki, Mohammed J.},
doi = {10.1007/978-3-030-30796-7_10},
file = {:D$\backslash$:/Kuliah/TA/DATA/ISWC19.pdf:pdf},
isbn = {9783030307950},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {October},
pages = {146--162},
title = {{FoodKG: A Semantics-Driven Knowledge Graph for Food Recommendation}},
volume = {11779 LNCS},
year = {2019}
}
@article{Feng2018,
abstract = {This paper presents a simple yet effective approach to unsupervisedly measuring Chinese lexical semantic similarity, and shows its promising performance in automatic story segmentation of Mandarin broadcast news. Our approach centers on the unsupervised correlated affinity graph (UCAG) model, which is initialized as a hybrid sparse graph, encoding both explicit word-to-word contextual correlations and latent word-to-character correlations within the given corpus. The UCAG model further diffuses the initial sparse correlations throughout the graph by parallel affinity propagation. This provides us with a dense, reliable, and corpus-specific lexical semantic similarity measure, which comes from purely unlabeled data. We then generalize the classical cosine similarity metric to effectively take soft similarities into account for story segmentation. Extensive experiments on benchmark datasets validate the superiority of the proposed similarity measure over previous measures. We specifically show that our similarity measure averagely helps to achieve 7.7{\%} relative F1-score improvement to the accuracy of state-of-art normalized cuts (NCuts) based story segmentation on two holistic benchmark Mandarin broadcast news corpora, TDT2 and CCTV, and achieves 10.8{\%} relative F1-score improvement on the detailed broadcast news subsets.},
author = {Feng, Wei and Nie, Xuecheng and Zhang, Yujun and Xie, Lei and Dang, Jianwu},
doi = {10.1016/j.neucom.2018.08.061},
file = {:D$\backslash$:/Kuliah/TA/DATA/1-s2.0-S0925231218310233-main.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Common character correlation,Contextual correlation,Generalized cosine similarity,Parallel affinity propagation,Story segmentation,Unsupervised correlated affinity graph (UCAG) mode},
pages = {236--247},
publisher = {Elsevier B.V.},
title = {{Unsupervised measure of Chinese lexical semantic similarity using correlated graph model for news story segmentation}},
url = {https://doi.org/10.1016/j.neucom.2018.08.061},
volume = {318},
year = {2018}
}
@article{Zhu2018,
abstract = {With the increasing popularity of large scale Knowledge Graph (KG)s, many applications such as semantic analysis, search and question answering need to link entity mentions in texts to entities in KGs. Because of the polysemy problem in natural language, entity disambiguation is thus a key problem in current research. Existing disambiguation methods have considered entity prominence, context similarity and entity-entity relatedness to discriminate ambiguous entities, which are mainly working on document or paragraph level texts containing rich contextual information, and based on lexical matching for computing context similarity. When meeting short texts containing limited contextual information, such as web queries, questions and tweets, those conventional disambiguation methods are not good at handling single entity mention and measuring context similarity. In order to enhance the performance of disambiguation methods based on context similarity with such short texts, we propose SCSNED method for disambiguation based on semantic similarity between contextual words and informative words of entities in KGs. Specially, we exploit the effectiveness of both knowledge-based and corpus-based semantic similarity methods for entity disambiguation with SCSNED. Moreover, we propose a Category2Vec embedding model based on joint learning of word and category embedding, in order to compute word-category similarity for entity disambiguation. We show the effectiveness of these proposed methods with illustrative examples, and evaluate their effectiveness in a comparative experiment for entity disambiguation in real world web queries, questions and tweets. The experimental results have identified the effectiveness of different semantic similarity methods, and demonstrated the improvement of semantic similarity methods in SCSNED and Category2Vec over the conventional context similarity baseline. We further compare the proposed approaches with the state of the art entity disambiguation systems and show the performances of the proposed approaches are among the best performing systems. In addition, one important feature of the proposed approaches using semantic similarity, is the potential application on any existing KGs since they mainly use common features of entity descriptions and categories. Another contribution of the paper is an updated survey on background of entity disambiguation in KGs and semantic similarity methods.},
author = {Zhu, Ganggao and Iglesias, Carlos A.},
doi = {10.1016/j.eswa.2018.02.011},
file = {:D$\backslash$:/Kuliah/TA/DATA/1-s2.0-S0957417418300897-main.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Context similarity,Entity linking,Knowledge graph,Named entity disambiguation,Semantic similarity,Word embedding},
pages = {8--24},
publisher = {Elsevier Ltd},
title = {{Exploiting semantic similarity for named entity disambiguation in knowledge graphs}},
url = {https://doi.org/10.1016/j.eswa.2018.02.011},
volume = {101},
year = {2018}
}
